{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":84493,"databundleVersionId":9871156,"sourceType":"competition"},{"sourceId":203900450,"sourceType":"kernelVersion"},{"sourceId":211920287,"sourceType":"kernelVersion"}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Inference\n\nIn this notebook I've experimented an approach to do online retraining of a simple lightgbm model.\n\n- EDA: https://www.kaggle.com/code/simonedegasperis/starter-eda\n- train: https://www.kaggle.com/code/simonedegasperis/lgbm-model-training\n\nKudos to https://www.kaggle.com/code/motono0223/js24-preprocessing-create-lags for historical data with added lags feature that I've used to train the initial version of the model.\n\nFor retraining I've sampled from each date of historical data a random 1% of the data and I've added online data. I tried to retrain the model each 100 batches by gradually increasing the cache which was defined as global variable and I've then averaged the solution of the initial model and the new retrained model.\n\nThe purpose of choosing a small fraction of data for retraining was to try to stay within 1 minute limit between 2 consecutive batches.\nI hope you will find the solution helpfull to build a better model.","metadata":{}},{"cell_type":"code","source":"# imports\nimport os\nimport glob\nimport numpy as np\nimport pandas as pd\nimport polars as pl\nimport lightgbm as lgb\nimport xgboost as xgb\nimport pickle\nimport kaggle_evaluation.jane_street_inference_server","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T10:12:11.654574Z","iopub.execute_input":"2024-12-12T10:12:11.655044Z","iopub.status.idle":"2024-12-12T10:12:16.835981Z","shell.execute_reply.started":"2024-12-12T10:12:11.654988Z","shell.execute_reply":"2024-12-12T10:12:16.834747Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport tqdm\nfrom pytorch_lightning import (LightningDataModule, LightningModule, Trainer)\nfrom pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint, Timer\nfrom statsmodels.tsa.arima.model import ARIMA","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T10:12:16.838074Z","iopub.execute_input":"2024-12-12T10:12:16.838610Z","iopub.status.idle":"2024-12-12T10:12:25.383703Z","shell.execute_reply.started":"2024-12-12T10:12:16.838572Z","shell.execute_reply":"2024-12-12T10:12:25.382674Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"class CONFIG:\n    seed = 42\n    target_col = \"responder_6\"\n    all_cols = [\"date_id\", \"symbol_id\", \"time_id\", \"weight\"] + [f\"feature_{idx:02d}\" for idx in range(79)]+ [f\"responder_{idx}_lag_1\" for idx in range(9)] + [target_col]\n    test_cols = [\"row_id\", \"date_id\", \"symbol_id\", \"time_id\"] + [f\"feature_{idx:02d}\" for idx in range(79)]+ [f\"responder_{idx}_lag_1\" for idx in range(9)] + [target_col]\n    feature_cols = [\"symbol_id\", \"time_id\"] + [f\"feature_{idx:02d}\" for idx in range(79)]+ [f\"responder_{idx}_lag_1\" for idx in range(9)]\n    only_features = [\"row_id\", \"date_id\", \"symbol_id\", \"time_id\"] + [f\"feature_{idx:02d}\" for idx in range(79)]\n    only_lags = [\"row_id\", \"date_id\", \"symbol_id\", \"time_id\"] + [f\"responder_{idx}_lag_1\" for idx in range(9)] \n    data_paths = [\"/kaggle/input/lgbm-model-training/lgbm_model_0.json\",\"/kaggle/input/js24-preprocessing-create-lags/training.parquet/\"]\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T10:12:25.385282Z","iopub.execute_input":"2024-12-12T10:12:25.386077Z","iopub.status.idle":"2024-12-12T10:12:25.394790Z","shell.execute_reply.started":"2024-12-12T10:12:25.386029Z","shell.execute_reply":"2024-12-12T10:12:25.393605Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"files = glob.glob(os.path.join(CONFIG.data_paths[1], \"*/*parquet\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T10:12:25.397971Z","iopub.execute_input":"2024-12-12T10:12:25.399092Z","iopub.status.idle":"2024-12-12T10:12:27.929845Z","shell.execute_reply.started":"2024-12-12T10:12:25.399038Z","shell.execute_reply":"2024-12-12T10:12:27.928690Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"files.sort()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T10:12:27.931135Z","iopub.execute_input":"2024-12-12T10:12:27.931454Z","iopub.status.idle":"2024-12-12T10:12:27.936819Z","shell.execute_reply.started":"2024-12-12T10:12:27.931424Z","shell.execute_reply":"2024-12-12T10:12:27.935511Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"pl_train = pl.concat([pl.read_parquet(_f, columns=CONFIG.all_cols).sample(fraction=0.01) for _f in files])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T10:12:27.938261Z","iopub.execute_input":"2024-12-12T10:12:27.938603Z","iopub.status.idle":"2024-12-12T10:12:58.605109Z","shell.execute_reply.started":"2024-12-12T10:12:27.938569Z","shell.execute_reply":"2024-12-12T10:12:58.603987Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"pl_train = pl_train.sort([\"date_id\", \"time_id\"])\npl_train = pl_train.with_row_count(name=\"row_id\")\npl_train = pl_train.with_columns(pl.col(\"row_id\").cast(pl.Int64))  # Ensure row_id is uint32\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T10:12:58.606397Z","iopub.execute_input":"2024-12-12T10:12:58.606710Z","iopub.status.idle":"2024-12-12T10:12:58.807730Z","shell.execute_reply.started":"2024-12-12T10:12:58.606683Z","shell.execute_reply":"2024-12-12T10:12:58.806522Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/3687664121.py:2: DeprecationWarning: `DataFrame.with_row_count` is deprecated. Use `with_row_index` instead. Note that the default column name has changed from 'row_nr' to 'index'.\n  pl_train = pl_train.with_row_count(name=\"row_id\")\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# load model\nlgbm_model = lgb.Booster(model_file=CONFIG.data_paths[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T10:12:58.809192Z","iopub.execute_input":"2024-12-12T10:12:58.809520Z","iopub.status.idle":"2024-12-12T10:12:58.872666Z","shell.execute_reply.started":"2024-12-12T10:12:58.809488Z","shell.execute_reply":"2024-12-12T10:12:58.871440Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Params used to retrain\ninput_params = {\"num_leaves\": 31, \"feature_fraction\": 0.8, \"n_estimators\": 50, \"learning_rate\": 0.1}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T10:12:58.874109Z","iopub.execute_input":"2024-12-12T10:12:58.874444Z","iopub.status.idle":"2024-12-12T10:12:58.880349Z","shell.execute_reply.started":"2024-12-12T10:12:58.874412Z","shell.execute_reply":"2024-12-12T10:12:58.878925Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Define Parameters\nparams = {\n    'objective': 'regression',\n    'metric': 'rmse',                                      # Root Mean Squared Error\n    'boosting_type': 'gbdt',                               # Gradient Boosted Decision Trees\n    'num_leaves': input_params['num_leaves'],\n    'learning_rate': input_params['learning_rate'],\n    'feature_fraction': input_params['feature_fraction'],\n    'n_estimators': input_params['n_estimators']      \n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T10:12:58.886695Z","iopub.execute_input":"2024-12-12T10:12:58.887728Z","iopub.status.idle":"2024-12-12T10:12:58.897281Z","shell.execute_reply.started":"2024-12-12T10:12:58.887669Z","shell.execute_reply":"2024-12-12T10:12:58.894249Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"# we use historical data with new data hold in a cache to retrain the model\npl_train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T10:12:58.898624Z","iopub.execute_input":"2024-12-12T10:12:58.899067Z","iopub.status.idle":"2024-12-12T10:12:58.938159Z","shell.execute_reply.started":"2024-12-12T10:12:58.899030Z","shell.execute_reply":"2024-12-12T10:12:58.936496Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"shape: (5, 94)\n┌────────┬─────────┬───────────┬─────────┬───┬─────────────┬─────────────┬────────────┬────────────┐\n│ row_id ┆ date_id ┆ symbol_id ┆ time_id ┆ … ┆ responder_6 ┆ responder_7 ┆ responder_ ┆ responder_ │\n│ ---    ┆ ---     ┆ ---       ┆ ---     ┆   ┆ _lag_1      ┆ _lag_1      ┆ 8_lag_1    ┆ 6          │\n│ i64    ┆ i16     ┆ i8        ┆ i16     ┆   ┆ ---         ┆ ---         ┆ ---        ┆ ---        │\n│        ┆         ┆           ┆         ┆   ┆ f32         ┆ f32         ┆ f32        ┆ f32        │\n╞════════╪═════════╪═══════════╪═════════╪═══╪═════════════╪═════════════╪════════════╪════════════╡\n│ 0      ┆ 1101    ┆ 14        ┆ 4       ┆ … ┆ null        ┆ null        ┆ null       ┆ 0.484299   │\n│ 1      ┆ 1101    ┆ 7         ┆ 8       ┆ … ┆ null        ┆ null        ┆ null       ┆ 0.139638   │\n│ 2      ┆ 1101    ┆ 8         ┆ 9       ┆ … ┆ null        ┆ null        ┆ null       ┆ 1.242788   │\n│ 3      ┆ 1101    ┆ 29        ┆ 16      ┆ … ┆ null        ┆ null        ┆ null       ┆ 1.183075   │\n│ 4      ┆ 1101    ┆ 31        ┆ 22      ┆ … ┆ null        ┆ null        ┆ null       ┆ 3.424516   │\n└────────┴─────────┴───────────┴─────────┴───┴─────────────┴─────────────┴────────────┴────────────┘","text/html":"<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (5, 94)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>row_id</th><th>date_id</th><th>symbol_id</th><th>time_id</th><th>weight</th><th>feature_00</th><th>feature_01</th><th>feature_02</th><th>feature_03</th><th>feature_04</th><th>feature_05</th><th>feature_06</th><th>feature_07</th><th>feature_08</th><th>feature_09</th><th>feature_10</th><th>feature_11</th><th>feature_12</th><th>feature_13</th><th>feature_14</th><th>feature_15</th><th>feature_16</th><th>feature_17</th><th>feature_18</th><th>feature_19</th><th>feature_20</th><th>feature_21</th><th>feature_22</th><th>feature_23</th><th>feature_24</th><th>feature_25</th><th>feature_26</th><th>feature_27</th><th>feature_28</th><th>feature_29</th><th>feature_30</th><th>feature_31</th><th>&hellip;</th><th>feature_52</th><th>feature_53</th><th>feature_54</th><th>feature_55</th><th>feature_56</th><th>feature_57</th><th>feature_58</th><th>feature_59</th><th>feature_60</th><th>feature_61</th><th>feature_62</th><th>feature_63</th><th>feature_64</th><th>feature_65</th><th>feature_66</th><th>feature_67</th><th>feature_68</th><th>feature_69</th><th>feature_70</th><th>feature_71</th><th>feature_72</th><th>feature_73</th><th>feature_74</th><th>feature_75</th><th>feature_76</th><th>feature_77</th><th>feature_78</th><th>responder_0_lag_1</th><th>responder_1_lag_1</th><th>responder_2_lag_1</th><th>responder_3_lag_1</th><th>responder_4_lag_1</th><th>responder_5_lag_1</th><th>responder_6_lag_1</th><th>responder_7_lag_1</th><th>responder_8_lag_1</th><th>responder_6</th></tr><tr><td>i64</td><td>i16</td><td>i8</td><td>i16</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>i8</td><td>i8</td><td>i16</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>&hellip;</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td></tr></thead><tbody><tr><td>0</td><td>1101</td><td>14</td><td>4</td><td>1.500934</td><td>-0.215145</td><td>1.179754</td><td>0.368541</td><td>0.038441</td><td>2.425909</td><td>-0.666875</td><td>-0.349467</td><td>-0.167756</td><td>0.757481</td><td>44</td><td>3</td><td>16</td><td>-0.875412</td><td>0.787212</td><td>0.033569</td><td>null</td><td>-0.341584</td><td>-0.484018</td><td>-2.238651</td><td>-1.171494</td><td>-0.038426</td><td>-0.194049</td><td>-0.384562</td><td>-0.559253</td><td>-0.755148</td><td>-0.12496</td><td>-0.27222</td><td>0.089473</td><td>0.053283</td><td>-0.810824</td><td>-0.437539</td><td>-0.240939</td><td>&hellip;</td><td>null</td><td>null</td><td>0.540745</td><td>null</td><td>-0.680334</td><td>2.469463</td><td>null</td><td>1.278344</td><td>0.748299</td><td>0.659961</td><td>-0.502885</td><td>-0.205055</td><td>-0.369538</td><td>-1.549924</td><td>-0.962902</td><td>-0.889017</td><td>0.174719</td><td>-0.21597</td><td>-0.604603</td><td>1.113999</td><td>0.40423</td><td>null</td><td>null</td><td>-0.155046</td><td>-0.141096</td><td>-0.197576</td><td>-0.202803</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.484299</td></tr><tr><td>1</td><td>1101</td><td>7</td><td>8</td><td>2.401405</td><td>0.093593</td><td>0.997003</td><td>0.40583</td><td>0.129569</td><td>2.524339</td><td>-0.971238</td><td>-0.659492</td><td>-0.630072</td><td>0.359726</td><td>11</td><td>7</td><td>76</td><td>-0.586538</td><td>1.09278</td><td>0.064694</td><td>null</td><td>1.88143</td><td>1.767255</td><td>-0.660556</td><td>-0.788979</td><td>0.415083</td><td>0.194781</td><td>0.787271</td><td>1.810799</td><td>-0.971642</td><td>-1.003009</td><td>-0.459541</td><td>-0.053719</td><td>-0.055635</td><td>1.282601</td><td>2.557373</td><td>0.18462</td><td>&hellip;</td><td>null</td><td>null</td><td>-2.608151</td><td>null</td><td>-1.203008</td><td>-0.18091</td><td>null</td><td>-0.75804</td><td>-0.281572</td><td>0.659961</td><td>0.107453</td><td>-0.237982</td><td>0.162273</td><td>-1.2511</td><td>-1.219487</td><td>-0.234532</td><td>1.713841</td><td>0.373077</td><td>-0.503657</td><td>0.248767</td><td>-0.404681</td><td>null</td><td>null</td><td>-0.28696</td><td>-0.285293</td><td>-0.210075</td><td>-0.221053</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.139638</td></tr><tr><td>2</td><td>1101</td><td>8</td><td>9</td><td>1.935522</td><td>-0.380708</td><td>0.912805</td><td>0.29319</td><td>0.444959</td><td>2.26886</td><td>-1.130615</td><td>-0.180222</td><td>-0.367418</td><td>0.406533</td><td>15</td><td>1</td><td>62</td><td>-0.951315</td><td>-0.064544</td><td>-0.155454</td><td>null</td><td>0.198297</td><td>0.09163</td><td>-0.593237</td><td>-1.17119</td><td>-0.215801</td><td>-0.106486</td><td>0.189968</td><td>0.358131</td><td>-0.339604</td><td>0.419127</td><td>0.520018</td><td>0.018472</td><td>-0.332786</td><td>0.005121</td><td>0.107359</td><td>-0.078926</td><td>&hellip;</td><td>null</td><td>null</td><td>-0.617989</td><td>null</td><td>-0.663403</td><td>0.731777</td><td>null</td><td>0.163533</td><td>-0.233739</td><td>0.659961</td><td>-0.336044</td><td>-0.284863</td><td>-0.372323</td><td>-1.379376</td><td>-1.203877</td><td>-0.400485</td><td>-0.065636</td><td>-0.070379</td><td>-0.938926</td><td>-0.016331</td><td>-0.210375</td><td>null</td><td>null</td><td>-0.265744</td><td>-0.203676</td><td>-0.290017</td><td>-0.244613</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1.242788</td></tr><tr><td>3</td><td>1101</td><td>29</td><td>16</td><td>1.611318</td><td>0.068022</td><td>1.369779</td><td>-0.121312</td><td>0.021666</td><td>2.044464</td><td>-0.452192</td><td>-0.14105</td><td>-0.142251</td><td>0.41963</td><td>57</td><td>1</td><td>336</td><td>-0.392691</td><td>1.63144</td><td>0.711133</td><td>null</td><td>-0.853772</td><td>-0.674342</td><td>-0.68171</td><td>-0.760426</td><td>0.458043</td><td>0.079794</td><td>-0.067636</td><td>-0.696882</td><td>0.634566</td><td>1.346142</td><td>0.440314</td><td>-1.532042</td><td>-1.723571</td><td>-0.607855</td><td>-0.980738</td><td>0.083502</td><td>&hellip;</td><td>null</td><td>null</td><td>0.113628</td><td>null</td><td>-2.539725</td><td>1.587884</td><td>-0.212709</td><td>-0.22311</td><td>-0.504644</td><td>0.659961</td><td>-0.387672</td><td>-0.298322</td><td>-0.3092</td><td>-0.862436</td><td>-1.649611</td><td>-0.491142</td><td>1.954723</td><td>0.344242</td><td>-0.497607</td><td>0.564821</td><td>0.517118</td><td>-0.208764</td><td>-0.218946</td><td>-0.066378</td><td>-0.093635</td><td>-0.128404</td><td>-0.157404</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1.183075</td></tr><tr><td>4</td><td>1101</td><td>31</td><td>22</td><td>1.05595</td><td>0.283426</td><td>1.454438</td><td>-0.1975</td><td>-0.124206</td><td>2.06975</td><td>-0.630104</td><td>0.068969</td><td>-0.033901</td><td>0.464361</td><td>44</td><td>3</td><td>24</td><td>0.091977</td><td>1.596405</td><td>1.848182</td><td>null</td><td>-0.325091</td><td>-0.588025</td><td>-0.145013</td><td>-0.714127</td><td>-0.41438</td><td>-0.039237</td><td>-0.778567</td><td>-0.642517</td><td>0.240914</td><td>1.054543</td><td>-1.100804</td><td>-1.319936</td><td>-0.728654</td><td>-0.675175</td><td>-0.598646</td><td>-0.064911</td><td>&hellip;</td><td>-1.526856</td><td>null</td><td>-1.261106</td><td>-2.338275</td><td>-2.559795</td><td>0.090784</td><td>-1.327383</td><td>-3.561138</td><td>-1.713163</td><td>0.659961</td><td>-0.170258</td><td>-0.311777</td><td>-0.258067</td><td>-0.927648</td><td>-1.393083</td><td>0.304107</td><td>2.576701</td><td>2.759911</td><td>-0.241112</td><td>0.438135</td><td>1.25564</td><td>0.071643</td><td>0.044431</td><td>0.706335</td><td>0.602444</td><td>0.248825</td><td>0.216596</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>3.424516</td></tr></tbody></table></div>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"# Initialize an empty DataFrame as the global cache\ncache = pl.DataFrame()\nbatch_count = 1\nnew_lgbm_model = None\n# hist_data = pl.DataFrame()\n# train = pl.DataFrame()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T10:12:58.939744Z","iopub.execute_input":"2024-12-12T10:12:58.940349Z","iopub.status.idle":"2024-12-12T10:12:58.947812Z","shell.execute_reply.started":"2024-12-12T10:12:58.940305Z","shell.execute_reply":"2024-12-12T10:12:58.946517Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"lags_ : pl.DataFrame | None = None\n# Replace this function with your inference code.\n# You can return either a Pandas or Polars dataframe, though Polars is recommended.\n# Each batch of predictions (except the very first) must be returned within 1 minute of the batch features being provided.\ndef predict(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame | pd.DataFrame:\n    \"\"\"Make a prediction.\"\"\"\n    # All the responders from the previous day are passed in at time_id == 0. We save them in a global variable for access at every time_id.\n    # Use them as extra features, if you like.\n    global cache          # Declare the global cache\n    global batch_count\n    global new_lgbm_model\n    # global train\n    # global hist_data\n\n    # Replace this section with your own predictions\n    predictions = test.select(\n        'row_id',\n        pl.lit(0.0).alias('responder_6'),\n    )\n\n    if not lags is None:\n        lags = lags.group_by([\"date_id\", \"symbol_id\"], maintain_order=True).last() # pick up last record of previous date\n        lags = lags.drop([\"time_id\"])\n        test = test.join(lags, on=[\"date_id\", \"symbol_id\"],  how=\"left\")\n    else:\n        test = test.with_columns(\n            ( pl.lit(0.0).alias(f'responder_{idx}_lag_1') for idx in range(9) )\n        )\n\n    if lags is not None:\n        print(f\"Filling cache for batch count {batch_count}\")\n        print(\"cache\")\n        print(cache.shape)\n        # print(cache.columns)\n        print(\"test\")\n        print(test.shape)\n        # print(test.columns)\n        # Update the global cache with new rows from test\n        cache = pl.concat([cache, test], rechunk=True)\n        \n\n    # initialize preds\n    preds = np.zeros((test.shape[0],))\n\n    # lightgbm model\n    X = test[CONFIG.feature_cols].to_numpy()\n  \n    # re-train a model on the fly every 30 batches\n    if batch_count % 100 == 0 and batch_count>=100:\n        print(\"---------------------------------------------------------------------------------------------\")\n        print(\"Using cache data to retrain the model\")\n        labels = cache[['date_id', 'symbol_id', 'responder_6_lag_1']]\n        labels = labels.group_by([\"date_id\", \"symbol_id\"], maintain_order=True).last()  # pick up last record of previous date\n        lag_cols_rename = {\"responder_6_lag_1\": \"responder_6\"}\n        labels = labels.rename(lag_cols_rename)\n        # I shift 1 day back because we know that responder_6_lag_1 correspond to the last recrd of the previous day\n        labels = labels.with_columns(\n            date_id = pl.col('date_id') - 1,  # lagged by 1 day\n        )\n        train = cache.group_by([\"date_id\", \"symbol_id\"], maintain_order=True).last()  # pick up last record of previous date\n        train = train.join(labels, on=[\"date_id\", \"symbol_id\"],  how=\"left\")\n        # merge with historic data before retraining\n        # print(\"Shape before merging with historic data\")\n        # print(\"New data\")\n        train = train.drop([\"is_scored\",\"weight\"])\n        # print(train.columns)\n        # print(train.shape)\n        # print(train.dtypes)\n        # print(\"Historical data\")\n        hist_data = pl_train.select(train.columns)\n        # print(hist_data.columns)\n        # print(hist_data.shape)\n        # print(hist_data.dtypes)\n\n        # Recasting columns of df1 to match the column types of df2\n        train = train.select([\n            pl.col(col).cast(hist_data.schema[col]) for col in hist_data.columns\n        ])\n\n        train = pl.concat([train, hist_data], rechunk=True)\n        print(\"Shape after merging with historic data\")  \n        print(train.shape)\n        # after this process we will obtain the labels\n        X_train = train[CONFIG.feature_cols].to_numpy()\n        y_train = train.select(CONFIG.target_col).to_numpy().flatten()\n\n        print(\"shape train data\")\n        print(X_train.shape)\n\n        print(\"shape labels\")\n        print(y_train.shape)       \n\n        train_data = lgb.Dataset(X_train, label=y_train)\n\n        # Re-train the model\n        new_lgbm_model = lgb.train(\n            params,\n            train_data,\n            num_boost_round=10\n        )\n\n    if new_lgbm_model:\n        # lightgbm model\n        y_pred1 = new_lgbm_model.predict(X, num_iteration=lgbm_model.best_iteration)\n        y_pred2 = lgbm_model.predict(X, num_iteration=lgbm_model.best_iteration)\n        y_pred = (y_pred1+y_pred2)/2\n    else:\n        # lightgbm model\n        y_pred = lgbm_model.predict(X, num_iteration=lgbm_model.best_iteration)\n\n    preds = y_pred\n    print(f\"predict> preds.shape =\", preds.shape)\n    \n    predictions = \\\n    test.select('row_id').\\\n    with_columns(\n        pl.Series(\n            name   = 'responder_6', \n            values = np.clip(preds, a_min = -5, a_max = 5),\n            dtype  = pl.Float64,\n        )\n    )\n\n    if isinstance(predictions, pl.DataFrame):\n        assert predictions.columns == ['row_id', 'responder_6']\n    elif isinstance(predictions, pd.DataFrame):\n        assert (predictions.columns == ['row_id', 'responder_6']).all()\n    else:\n        raise TypeError('The predict function must return a DataFrame')\n    # Confirm has as many rows as the test data.\n    assert len(predictions) == len(test)\n\n    batch_count+=1\n\n    return predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T10:12:58.949224Z","iopub.execute_input":"2024-12-12T10:12:58.949624Z","iopub.status.idle":"2024-12-12T10:12:58.976077Z","shell.execute_reply.started":"2024-12-12T10:12:58.949587Z","shell.execute_reply":"2024-12-12T10:12:58.974171Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# test = pl.read_parquet('/kaggle/input/jane-street-real-time-market-data-forecasting/test.parquet')\n# lags = pl.read_parquet('/kaggle/input/jane-street-real-time-market-data-forecasting/lags.parquet')\n# predict(test, lags)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T10:12:58.977672Z","iopub.execute_input":"2024-12-12T10:12:58.978166Z","iopub.status.idle":"2024-12-12T10:12:59.002069Z","shell.execute_reply.started":"2024-12-12T10:12:58.978107Z","shell.execute_reply":"2024-12-12T10:12:59.000554Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"inference_server = kaggle_evaluation.jane_street_inference_server.JSInferenceServer(predict)\n\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    inference_server.serve()\nelse:\n    inference_server.run_local_gateway(\n        (\n            '/kaggle/input/jane-street-real-time-market-data-forecasting/test.parquet',\n            '/kaggle/input/jane-street-real-time-market-data-forecasting/lags.parquet',\n        )\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T10:12:59.003228Z","iopub.execute_input":"2024-12-12T10:12:59.003743Z","iopub.status.idle":"2024-12-12T10:12:59.261455Z","shell.execute_reply.started":"2024-12-12T10:12:59.003699Z","shell.execute_reply":"2024-12-12T10:12:59.260032Z"}},"outputs":[{"name":"stdout","text":"Filling cache for batch count 1\ncache\n(0, 0)\ntest\n(39, 94)\npredict> preds.shape = (39,)\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}